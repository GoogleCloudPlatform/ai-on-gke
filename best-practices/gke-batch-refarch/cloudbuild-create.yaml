# Copyright 2023 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

timeout: 3600s
steps:
  - name: "gcr.io/kaniko-project/executor:v1.20.1-slim"
    dir: "gke-batch-refarch"
    id: "Build Installer Image"
    waitFor: 
    - "-"
    args:
      - --destination=${_REGION}-docker.pkg.dev/${PROJECT_ID}/tutorial-installer/installer
      - --cache=true
      - --cache-ttl=12h

  # TODO: Would be better to do this with crane
  - name: "${_REGION}-docker.pkg.dev/${PROJECT_ID}/tutorial-installer/installer"
    id: "Push workload image to Artifact Registry: pytorch-gpu"
    dir: "gke-batch-refarch"
    entrypoint: "ash"
    waitFor: 
    - "Build Installer Image"
    args:
      - "-xe"
      - "-c"
      - |
        echo y | gcloud auth configure-docker ${_REGION}-docker.pkg.dev && \
        if ! gcloud artifacts docker images describe ${_REGION}-docker.pkg.dev/${PROJECT_ID}/tutorial-installer/pytorch-gpu.1-12:v1 &> /dev/null; then
          docker pull gcr.io/deeplearning-platform-release/pytorch-gpu.1-12:m109 && \
          docker tag gcr.io/deeplearning-platform-release/pytorch-gpu.1-12:m109 ${_REGION}-docker.pkg.dev/${PROJECT_ID}/tutorial-installer/pytorch-gpu.1-12:v1 && \
          docker push ${_REGION}-docker.pkg.dev/${PROJECT_ID}/tutorial-installer/pytorch-gpu.1-12:v1
        fi
  
  - name: "${_REGION}-docker.pkg.dev/${PROJECT_ID}/tutorial-installer/installer"
    id: "Push workload image to Artifact Registry: pytorch-mnist"
    dir: "gke-batch-refarch/jobset"
    entrypoint: "ash"
    waitFor: 
    - "Build Installer Image"
    args:
      - "-xe"
      - "-c"
      - |
        echo y | gcloud auth configure-docker ${_REGION}-docker.pkg.dev && \
        if ! gcloud artifacts docker images describe ${_REGION}-docker.pkg.dev/${PROJECT_ID}/tutorial-installer/pytorch-mnist:v1 &> /dev/null; then
          docker build -t ${_REGION}-docker.pkg.dev/${PROJECT_ID}/tutorial-installer/pytorch-mnist:v1 . && \
          docker push ${_REGION}-docker.pkg.dev/${PROJECT_ID}/tutorial-installer/pytorch-mnist:v1
        fi

  - name: "${_REGION}-docker.pkg.dev/${PROJECT_ID}/tutorial-installer/installer"
    id: "Push workload image to Artifact Registry: finetune-gemma-gpu"
    dir: "gke-batch-refarch"
    entrypoint: "ash"
    waitFor: 
    - "Build Installer Image"
    args:
      - "-xe"
      - "-c"
      - |
        echo y | gcloud auth configure-docker ${_REGION}-docker.pkg.dev && \
        if ! gcloud artifacts docker images describe us-docker.pkg.dev/${PROJECT_ID}/gemma/finetune-gemma-gpu:1.0.0 &> /dev/null; then
          git clone https://github.com/GoogleCloudPlatform/kubernetes-engine-samples && \
          cd kubernetes-engine-samples/ai-ml/llm-finetuning-gemma && \
          gcloud builds submit .
        fi
  
  - name: "${_REGION}-docker.pkg.dev/${PROJECT_ID}/tutorial-installer/installer"
    id: "Setup GKE"
    dir: "ml-platform/examples/cluster"
    entrypoint: "ash"
    waitFor:
    - "Build Installer Image"
    args:
      - "-xe"
      - "-c"
      - |
        TF_VAR_cluster_name_prefix="${_CLUSTER_NAME_PREFIX}"
        TF_VAR_enable_private_endpoint="${_ENABLE_PRIVATE_ENDPOINTS}"
        TF_VAR_environment_name="${_ENVIRONMENT_NAME}"
        TF_VAR_environment_project_id="${PROJECT_ID}"
        TF_VAR_region="${_REGION}"
        #TF_VAR_zone="${_ZONE}"

        tf_variables="-var cluster_name_prefix=${TF_VAR_cluster_name_prefix} -var enable_private_endpoint=${TF_VAR_enable_private_endpoint} -var environment_name=${TF_VAR_environment_name} -var environment_project_id=${TF_VAR_environment_project_id} -var region=${TF_VAR_region}"

        if gcloud storage buckets describe gs://${TF_VAR_environment_project_id}-batch-${TF_VAR_environment_name}-terraform &> /dev/null; then
          export TF_VAR_create_terraform_bucket="false"
        fi

        # Initialize
        cd initialize && \
        terraform init -no-color && \
        terraform apply -auto-approve -input=false -no-color ${tf_variables} && \
        rm tfplan && \
        cp backend.tf backend.tf.local && \
        cp backend.tf.bucket backend.tf && \

        if [ ${TF_VAR_create_terraform_bucket} != "false" ]; then
          terraform init -force-copy -migrate-state -no-color && \
          rm -rf state || exit 1
        fi

        cd ..
        
        # Networking
        cd networking && \
        terraform init -no-color && \
        terraform plan -input=false -no-color -out=tfplan ${tf_variables} && \
        terraform apply -input=false -no-color tfplan && \
        rm tfplan || exit 1
        cd ..

        # Container cluster
        cd container_cluster && \
        terraform init -no-color && \
        terraform plan -input=false -no-color -out=tfplan ${tf_variables} && \
        terraform apply -input=false -no-color tfplan && \
        rm tfplan  || exit 1
        cd ..

        # Workloads
        cd workloads && \
        terraform init -no-color && \
        terraform plan -input=false -no-color -out=tfplan ${tf_variables} && \
        terraform apply -input=false -no-color tfplan && \
        rm tfplan  || exit 1
        cd ..

        # Get cluster credentials
        gcloud container clusters get-credentials ${TF_VAR_cluster_name_prefix}-${TF_VAR_environment_name} --region=${_REGION} --project=${PROJECT_ID}

  - name: "${_REGION}-docker.pkg.dev/${PROJECT_ID}/tutorial-installer/installer"
    id: "Configure GKE for Batch Reference Architecture"
    dir: "gke-batch-refarch/gke"
    entrypoint: "ash"
    waitFor:
      ["Build Installer Image", "Setup GKE"]
    args:
      - "-xe"
      - "-c"
      - |
        terraform init -backend-config="bucket=${PROJECT_ID}-batch-dev-terraform" -var="project_id=${PROJECT_ID}" -var="region=${_REGION}" -var="zone=${_ZONE}" -no-color && \
        terraform plan -out terraform.tfplan -var="project_id=${PROJECT_ID}" -var="region=${_REGION}" -var="zone=${_ZONE}" -no-color && \
        terraform apply -input=false -lock=false terraform.tfplan -no-color && \
        rm terraform.tfplan

  - name: "${_REGION}-docker.pkg.dev/${PROJECT_ID}/tutorial-installer/installer"
    id: "Install Kueue and JobSet"
    entrypoint: "ash"
    waitFor: 
      ["Setup GKE", "Configure GKE for Batch Reference Architecture"]
    args:
      - "-xe"
      - "-c"
      - |
        kubectl apply --server-side -f https://github.com/kubernetes-sigs/jobset/releases/download/v0.6.0/manifests.yaml && \
        kubectl -n jobset-system wait --for condition=established --timeout=120s customresourcedefinition.apiextensions.k8s.io/jobsets.jobset.x-k8s.io && \
        kubectl apply --server-side -f "https://github.com/kubernetes-sigs/kueue/releases/download/v0.8.1/manifests.yaml" && \
        kubectl -n kueue-system wait --for condition=established --timeout=120s crd/clusterqueues.kueue.x-k8s.io && \
        kubectl -n kueue-system wait --for condition=established --timeout=120s crd/localqueues.kueue.x-k8s.io && \
        kubectl -n kueue-system wait --for condition=established --timeout=120s crd/resourceflavors.kueue.x-k8s.io && \
        kubectl -n kueue-system wait --for condition=established --timeout=120s crd/workloads.kueue.x-k8s.io

  - name: "${_REGION}-docker.pkg.dev/${PROJECT_ID}/tutorial-installer/installer"
    id: "Deploy platform config: Priority Classes, teams, Kueue and monitoring configuration"
    dir: "gke-batch-refarch/platform"
    entrypoint: "ash"
    waitFor:
    - "Setup GKE"
    - "Configure GKE for Batch Reference Architecture"
    - "Install Kueue and JobSet"
    - "Push workload image to Artifact Registry: pytorch-gpu"
    - "Push workload image to Artifact Registry: pytorch-mnist"
    args:
      - "-xe"
      - "-c"
      - |
        kubectl -n kueue-system wait --for condition=established --timeout=120s crd/clusterqueues.kueue.x-k8s.io && \
        kubectl -n kueue-system wait --for condition=established --timeout=120s crd/localqueues.kueue.x-k8s.io && \
        kubectl -n kueue-system wait --for condition=established --timeout=120s crd/resourceflavors.kueue.x-k8s.io && \
        kubectl -n kueue-system wait --for condition=established --timeout=120s crd/workloads.kueue.x-k8s.io && \
        kubectl apply -f priorityclass && \
        kubectl apply -f teams && \
        kubectl apply -f kueue && \
        export PROJECT_ID=${PROJECT_ID} && \
        export REGION=${_REGION} && \
        ./monitoring/install-prometheus.sh && \
        ./monitoring/gmp/install-gmp.sh

##########################################################################################
options:
  logging: CLOUD_LOGGING_ONLY
substitutions:
  # default values
  _CLUSTER_NAME_PREFIX: "batch"
  _ENABLE_PRIVATE_ENDPOINTS: "false"
  _ENVIRONMENT_NAME: "dev"
