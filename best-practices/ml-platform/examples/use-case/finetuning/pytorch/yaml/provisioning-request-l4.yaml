apiVersion: v1
kind: PodTemplate
metadata:
  name: l4-job-J_ID
  namespace: ml-team
template:
  spec:
    nodeSelector:
      cloud.google.com/gke-nodepool: gpu-l4x2-g2s24-dws
    tolerations:
    - key: "nvidia.com/gpu"
      operator: "Exists"
      effect: "NoSchedule"
    - key: "on-demand"
      value: "true"
      operator: "Equal"
      effect: "NoSchedule"
    containers:
    - name: pi
      image: perl
      command: ["/bin/sh"]
      resources:
        limits:
          cpu: "700m"
          nvidia.com/gpu: 2
        requests:
          cpu: "700m"
          nvidia.com/gpu: 2
    restartPolicy: Never
---
apiVersion: autoscaling.x-k8s.io/v1beta1
kind: ProvisioningRequest
metadata:
  name: l4-job-J_ID
  namespace: ml-team
spec:
  provisioningClassName: queued-provisioning.gke.io
  parameters:
    maxRunDurationSeconds: "86400"
  podSets:
  - count: 2
    podTemplateRef:
      name: l4-job-J_ID
