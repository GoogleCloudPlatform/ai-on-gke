{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7221da7f-3eee-469a-bfec-71bd1c4967aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install all dependencies\n",
    "!pip install \"ray==2.7.1\"\n",
    "!pip install ray[train]\n",
    "!pip install torch --no-cache-dir\n",
    "!pip install torchvision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2849bed-2fed-4123-bf96-ba24c1dfd0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from filelock import FileLock\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9628b3d7-57ac-42fa-a955-ead43871719c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor, Normalize\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b18fc4-3807-4801-ace7-b3e1bdb720f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray.train\n",
    "from ray.train import ScalingConfig\n",
    "from ray.train.torch import TorchTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83e9d96-50e1-4609-8cb1-4276125ebc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.init(\n",
    "    address=\"ray://example-cluster-kuberay-head-svc:10001\",\n",
    "    runtime_env={\n",
    "        \"pip\": [\n",
    "            \"IPython\",\n",
    "            \"torch\",\n",
    "            \"torchvision\",\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb04580-b5c7-46b7-91b9-7b0ef400626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(batch_size):\n",
    "    # Transform to normalize the input images\n",
    "    transform = transforms.Compose([ToTensor(), Normalize((0.5,), (0.5,))])\n",
    "\n",
    "    with FileLock(os.path.expanduser(\"~/data.lock\")):\n",
    "        # Download training data from open datasets.\n",
    "        training_data = datasets.FashionMNIST(\n",
    "            root=\"~/data\",\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=transform,\n",
    "        )\n",
    "\n",
    "        # Download test data from open datasets.\n",
    "        test_data = datasets.FashionMNIST(\n",
    "            root=\"~/data\",\n",
    "            train=False,\n",
    "            download=True,\n",
    "            transform=transform,\n",
    "        )\n",
    "\n",
    "    # Create data loaders.\n",
    "    train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "    return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defa8864-129c-4fb5-8aff-f814b443abdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb1ba53-536a-4c92-bf4c-f2787807118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func_per_worker(config: Dict):\n",
    "    lr = config[\"lr\"]\n",
    "    epochs = config[\"epochs\"]\n",
    "    batch_size = config[\"batch_size_per_worker\"]\n",
    "\n",
    "    # Get dataloaders inside worker training function\n",
    "    train_dataloader, test_dataloader = get_dataloaders(batch_size=batch_size)\n",
    "\n",
    "    # [1] Prepare Dataloader for distributed training\n",
    "    # Shard the datasets among workers and move batches to the correct device\n",
    "    # =======================================================================\n",
    "    train_dataloader = ray.train.torch.prepare_data_loader(train_dataloader)\n",
    "    test_dataloader = ray.train.torch.prepare_data_loader(test_dataloader)\n",
    "\n",
    "    model = NeuralNetwork()\n",
    "\n",
    "    # [2] Prepare and wrap your model with DistributedDataParallel\n",
    "    # Move the model the correct GPU/CPU device\n",
    "    # ============================================================\n",
    "    model = ray.train.torch.prepare_model(model)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "    # Model training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for X, y in tqdm(train_dataloader, desc=f\"Train Epoch {epoch}\"):\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        test_loss, num_correct, num_total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for X, y in tqdm(test_dataloader, desc=f\"Test Epoch {epoch}\"):\n",
    "                pred = model(X)\n",
    "                loss = loss_fn(pred, y)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                num_total += y.shape[0]\n",
    "                num_correct += (pred.argmax(1) == y).sum().item()\n",
    "\n",
    "        test_loss /= len(test_dataloader)\n",
    "        accuracy = num_correct / num_total\n",
    "\n",
    "        # [3] Report metrics to Ray Train\n",
    "        # ===============================\n",
    "        ray.train.report(metrics={\"loss\": test_loss, \"accuracy\": accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403e3dd4-cf9e-47ac-b018-77e9f9fcc751",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fashion_mnist(num_workers=2, use_gpu=False):\n",
    "    global_batch_size = 32\n",
    "\n",
    "    train_config = {\n",
    "        \"lr\": 1e-3,\n",
    "        \"epochs\": 10,\n",
    "        \"batch_size_per_worker\": global_batch_size // num_workers,\n",
    "    }\n",
    "\n",
    "    # Configure computation resources\n",
    "    scaling_config = ScalingConfig(num_workers=num_workers, use_gpu=use_gpu)\n",
    "\n",
    "    # Initialize a Ray TorchTrainer\n",
    "    trainer = TorchTrainer(\n",
    "        train_loop_per_worker=train_func_per_worker,\n",
    "        train_loop_config=train_config,\n",
    "        scaling_config=scaling_config,\n",
    "    )\n",
    "\n",
    "    # [4] Start Distributed Training\n",
    "    # Run `train_func_per_worker` on all workers\n",
    "    # =============================================\n",
    "    result = trainer.fit()\n",
    "    print(f\"Training result: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baf1f5e-47d6-443d-b0f4-eba63f9593d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_fashion_mnist(num_workers=2, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade4524f-fbfa-49c3-9256-0e8a48e2f7b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
