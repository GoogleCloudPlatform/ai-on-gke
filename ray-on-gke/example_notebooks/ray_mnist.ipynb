{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d10feeb-9329-4da5-aa26-1e446f1c0ab2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 23:15:46.583781: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import tensorflow as tf\n",
    "\n",
    "from ray.air import session\n",
    "from ray.air.integrations.keras import Callback\n",
    "from ray.train.tensorflow import TensorflowTrainer\n",
    "from ray.air.config import ScalingConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f806c128-2ceb-4f13-bcf1-d7ecf0f2adc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If using GPUs, set this to True.\n",
    "use_gpu = True\n",
    "\n",
    "a = 5\n",
    "b = 10\n",
    "size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a8bdca7-ccf3-4f07-893c-cd76d782d10f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model() -> tf.keras.Model:\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=()),\n",
    "            # Add feature dimension, expanding (batch_size,) to (batch_size, 1).\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(10),\n",
    "            tf.keras.layers.Dense(1),\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_func(config: dict):\n",
    "    batch_size = config.get(\"batch_size\", 64)\n",
    "    epochs = config.get(\"epochs\", 3)\n",
    "\n",
    "    strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
    "    with strategy.scope():\n",
    "        # Model building/compiling need to be within `strategy.scope()`.\n",
    "        multi_worker_model = build_model()\n",
    "        multi_worker_model.compile(\n",
    "            optimizer=tf.keras.optimizers.SGD(learning_rate=config.get(\"lr\", 1e-3)),\n",
    "            loss=tf.keras.losses.mean_squared_error,\n",
    "            metrics=[tf.keras.metrics.mean_squared_error],\n",
    "        )\n",
    "\n",
    "    dataset = session.get_dataset_shard(\"train\")\n",
    "\n",
    "    results = []\n",
    "    for _ in range(epochs):\n",
    "        tf_dataset = dataset.to_tf(\n",
    "            feature_columns=\"x\", label_columns=\"y\", batch_size=batch_size\n",
    "        )\n",
    "        history = multi_worker_model.fit(tf_dataset, callbacks=[Callback()])\n",
    "        results.append(history.history)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d83a394-b233-4b16-9726-4632e9600803",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.10.9</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.3.0</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://10.8.7.8:8265\" target=\"_blank\">http://10.8.7.8:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "ClientContext(dashboard_url='10.8.7.8:8265', python_version='3.10.9', ray_version='2.3.0', ray_commit='cf7a56b4b0b648c324722df7c99c168e92ff0b45', protocol_version='2022-12-06', _num_clients=1, _context_to_restore=<ray.util.client._ClientContext object at 0x7fa82ca28610>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(\"ray://example-cluster-kuberay-head-svc.ray.svc.cluster.local:10001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7811e187-824a-4728-97e6-1514f467b019",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\"lr\": 1e-3, \"batch_size\": 32, \"epochs\": 4}\n",
    "\n",
    "train_dataset = ray.data.from_items(\n",
    "    [{\"x\": x / 200, \"y\": 2 * x / 200} for x in range(200)]\n",
    ")\n",
    "scaling_config = ScalingConfig(num_workers=2, use_gpu=use_gpu)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbcf802e-0e34-4cd9-a651-303f0353dea5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m 2023-04-06 16:16:12.231770: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m 2023-04-06 16:16:12.234316: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m 2023-04-06 16:16:12.291769: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m 2023-04-06 16:16:12.292305: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m 2023-04-06 16:16:13.269462: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-04-06 16:16:33</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:18.51        </td></tr>\n",
       "<tr><td>Memory:      </td><td>3.2/83.5 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 0/3 CPUs, 0/3 GPUs, 0.0/3.73 GiB heap, 0.0/0.99 GiB objects (0.0/3.0 accelerator_type:A100)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc         </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  mean_squared_error</th><th style=\"text-align: right;\">  _timestamp</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TensorflowTrainer_072e8_00000</td><td>TERMINATED</td><td>10.8.7.8:999</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">          10.117</td><td style=\"text-align: right;\">0.928824</td><td style=\"text-align: right;\">            0.928824</td><td style=\"text-align: right;\">  1680822991</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=999)\u001b[0m 2023-04-06 16:16:18.754198: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[2m\u001b[36m(pid=999)\u001b[0m 2023-04-06 16:16:18.777738: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "\u001b[2m\u001b[36m(pid=999)\u001b[0m 2023-04-06 16:16:18.830744: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "\u001b[2m\u001b[36m(pid=999)\u001b[0m 2023-04-06 16:16:18.831326: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[2m\u001b[36m(pid=999)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(pid=999)\u001b[0m 2023-04-06 16:16:19.897479: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m 2023-04-06 16:16:23.825772: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m 2023-04-06 16:16:23.829022: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m 2023-04-06 16:16:23.833699: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m 2023-04-06 16:16:23.836469: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m 2023-04-06 16:16:23.882863: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m 2023-04-06 16:16:23.883451: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m 2023-04-06 16:16:23.903021: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m 2023-04-06 16:16:23.903550: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m 2023-04-06 16:16:24.815414: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m 2023-04-06 16:16:24.950939: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[2m\u001b[36m(TensorflowTrainer pid=999)\u001b[0m 2023-04-06 16:16:25,935\tINFO bulk_executor.py:39 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[randomize_block_order]\n",
      "\u001b[2m\u001b[36m(TensorflowTrainer pid=999)\u001b[0m /home/ray/anaconda3/lib/python3.10/site-packages/ray/data/_internal/bulk_dataset_iterator.py:108: UserWarning: session.get_dataset_shard returns a ray.data.DatasetIterator instead of a Dataset as of Ray v2.3. Use iter_torch_batches(), to_tf(), or iter_batches() to iterate over one epoch. See https://docs.ray.io/en/latest/data/api/dataset_iterator.html for full DatasetIterator docs.\n",
      "\u001b[2m\u001b[36m(TensorflowTrainer pid=999)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m 2023-04-06 16:16:26.026073: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: example-cluster-kuberay-worker-workergroup-dw77g\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m 2023-04-06 16:16:26.026142: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: example-cluster-kuberay-worker-workergroup-dw77g\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m 2023-04-06 16:16:26.026227: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m 2023-04-06 16:16:26.026265: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 470.161.3\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m 2023-04-06 16:16:26.033349: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:450] Started server with target: grpc://10.8.8.8:47851\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m 2023-04-06 16:16:26.040715: I tensorflow/tsl/distributed_runtime/coordination/coordination_service.cc:525] /job:worker/replica:0/task:0 has connected to coordination service. Incarnation: 6656391604461883464\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m 2023-04-06 16:16:26.041023: I tensorflow/tsl/distributed_runtime/coordination/coordination_service_agent.cc:298] Coordination agent has successfully connected.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m 2023-04-06 16:16:26.026232: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: example-cluster-kuberay-head-8jw8d\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m 2023-04-06 16:16:26.026259: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: example-cluster-kuberay-head-8jw8d\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m 2023-04-06 16:16:26.026330: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m 2023-04-06 16:16:26.026365: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 470.161.3\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m 2023-04-06 16:16:26.033579: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:450] Started server with target: grpc://10.8.7.8:39057\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m 2023-04-06 16:16:26.078956: I tensorflow/tsl/distributed_runtime/coordination/coordination_service_agent.cc:298] Coordination agent has successfully connected.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m 2023-04-06 16:16:26.078719: I tensorflow/tsl/distributed_runtime/coordination/coordination_service.cc:525] /job:worker/replica:0/task:1 has connected to coordination service. Incarnation: 5542558259281313806\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m 2023-04-06 16:16:26.491021: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m \t [[{{node Placeholder/_0}}]]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m 2023-04-06 16:16:26.543274: W tensorflow/core/framework/dataset.cc:807] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m 2023-04-06 16:16:26.543636: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m \t [[{{node Placeholder/_0}}]]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m 2023-04-06 16:16:26.679770: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m \t [[{{node Placeholder/_0}}]]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m 2023-04-06 16:16:26.585125: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m \t [[{{node Placeholder/_0}}]]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m 2023-04-06 16:16:26.628529: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m \t [[{{node Placeholder/_0}}]]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m 2023-04-06 16:16:26.732184: W tensorflow/core/framework/dataset.cc:807] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m 2023-04-06 16:16:26.732549: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m \t [[{{node Placeholder/_0}}]]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m 2023-04-06 16:16:26.752001: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m \t [[{{node Placeholder/_0}}]]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m 2023-04-06 16:16:26.793740: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m \t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2/Unknown - 1s 55ms/step - loss: 3.3150 - mean_squared_error: 3.3150\n",
      "      2/Unknown - 1s 55ms/step - loss: 3.3150 - mean_squared_error: 3.3150\n",
      "      3/Unknown - 1s 76ms/step - loss: 3.0522 - mean_squared_error: 3.0522\n",
      "      3/Unknown - 1s 75ms/step - loss: 3.0522 - mean_squared_error: 3.0522\n",
      "      5/Unknown - 2s 63ms/step - loss: 2.7236 - mean_squared_error: 2.7236\n",
      "      5/Unknown - 1s 63ms/step - loss: 2.7236 - mean_squared_error: 2.7236\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m Result for TensorflowTrainer_072e8_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   _time_this_iter_s: 2.651543140411377\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   _timestamp: 1680822988\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   _training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   date: 2023-04-06_16-16-28\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   experiment_id: f2d05e60392044ee96706251fcdd2a67\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   hostname: example-cluster-kuberay-head-8jw8d\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   loss: 1.3728505373001099\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   mean_squared_error: 1.3728505373001099\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   node_ip: 10.8.7.8\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   pid: 999\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   should_checkpoint: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   time_since_restore: 7.628103971481323\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   time_this_iter_s: 7.628103971481323\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   time_total_s: 7.628103971481323\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   timestamp: 1680822988\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   trial_id: 072e8_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   warmup_time: 0.03273630142211914\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   \n",
      "8/8 [==============================] - 2s 128ms/step - loss: 1.3729 - mean_squared_error: 1.3729\n",
      "8/8 [==============================] - 2s 128ms/step - loss: 1.3729 - mean_squared_error: 1.3729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m 2023-04-06 16:16:28.862638: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m \t [[{{node Placeholder/_0}}]]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m 2023-04-06 16:16:28.894461: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m \t [[{{node Placeholder/_0}}]]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m 2023-04-06 16:16:28.989445: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m \t [[{{node Placeholder/_0}}]]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m 2023-04-06 16:16:28.909581: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m \t [[{{node Placeholder/_0}}]]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m 2023-04-06 16:16:28.926600: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m \t [[{{node Placeholder/_0}}]]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m 2023-04-06 16:16:28.978426: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m \t [[{{node Placeholder/_0}}]]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m 2023-04-06 16:16:29.006733: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m \t [[{{node Placeholder/_0}}]]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m 2023-04-06 16:16:29.048830: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m \t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1/Unknown - 0s 85ms/step - loss: 3.0830 - mean_squared_error: 3.0830\n",
      "      2/Unknown - 0s 87ms/step - loss: 2.9205 - mean_squared_error: 2.9205\n",
      "      2/Unknown - 0s 87ms/step - loss: 2.9205 - mean_squared_error: 2.9205\n",
      "      6/Unknown - 0s 38ms/step - loss: 2.3748 - mean_squared_error: 2.3748\n",
      "      6/Unknown - 0s 38ms/step - loss: 2.3748 - mean_squared_error: 2.3748\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 1.2023 - mean_squared_error: 1.2023\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 1.2023 - mean_squared_error: 1.2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m 2023-04-06 16:16:29.639782: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m \t [[{{node Placeholder/_0}}]]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m 2023-04-06 16:16:29.678426: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m \t [[{{node Placeholder/_0}}]]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m 2023-04-06 16:16:29.685200: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m \t [[{{node Placeholder/_0}}]]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m 2023-04-06 16:16:29.702306: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m \t [[{{node Placeholder/_0}}]]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m 2023-04-06 16:16:29.757436: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m \t [[{{node Placeholder/_0}}]]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m 2023-04-06 16:16:29.726005: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m \t [[{{node Placeholder/_0}}]]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m 2023-04-06 16:16:29.742562: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m \t [[{{node Placeholder/_0}}]]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m 2023-04-06 16:16:29.818418: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m \t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1/Unknown - 0s 96ms/step - loss: 2.7288 - mean_squared_error: 2.7288\n",
      "      1/Unknown - 0s 97ms/step - loss: 2.7288 - mean_squared_error: 2.7288\n",
      "      3/Unknown - 0s 52ms/step - loss: 2.3659 - mean_squared_error: 2.3659\n",
      "      6/Unknown - 0s 40ms/step - loss: 2.0840 - mean_squared_error: 2.0840\n",
      "      6/Unknown - 0s 40ms/step - loss: 2.0840 - mean_squared_error: 2.0840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m 2023-04-06 16:16:30.478433: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m \t [[{{node Placeholder/_0}}]]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m 2023-04-06 16:16:30.444526: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m \t [[{{node Placeholder/_0}}]]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m 2023-04-06 16:16:30.486778: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m \t [[{{node Placeholder/_0}}]]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m 2023-04-06 16:16:30.522028: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m \t [[{{node Placeholder/_0}}]]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m 2023-04-06 16:16:30.538287: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m \t [[{{node Placeholder/_0}}]]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m 2023-04-06 16:16:30.503593: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m \t [[{{node Placeholder/_0}}]]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m 2023-04-06 16:16:30.559958: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=213, ip=10.8.8.8)\u001b[0m \t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 60ms/step - loss: 1.0555 - mean_squared_error: 1.0555\n",
      "8/8 [==============================] - 1s 60ms/step - loss: 1.0555 - mean_squared_error: 1.0555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m 2023-04-06 16:16:30.620110: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=1146)\u001b[0m \t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1/Unknown - 0s 137ms/step - loss: 2.4216 - mean_squared_error: 2.4216\n",
      "      1/Unknown - 0s 137ms/step - loss: 2.4216 - mean_squared_error: 2.4216\n",
      "      2/Unknown - 0s 90ms/step - loss: 2.2835 - mean_squared_error: 2.2835 \n",
      "      2/Unknown - 0s 90ms/step - loss: 2.2835 - mean_squared_error: 2.2835 \n",
      "      4/Unknown - 0s 65ms/step - loss: 1.8886 - mean_squared_error: 1.8886\n",
      "      4/Unknown - 0s 65ms/step - loss: 1.8886 - mean_squared_error: 1.8886\n",
      "      7/Unknown - 0s 49ms/step - loss: 1.8287 - mean_squared_error: 1.8287\n",
      "      7/Unknown - 0s 49ms/step - loss: 1.8287 - mean_squared_error: 1.8287\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.9288 - mean_squared_error: 0.9288\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.9288 - mean_squared_error: 0.9288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m 2023-04-06 16:16:33,798\tINFO tune.py:798 -- Total run time: 18.59 seconds (18.50 seconds for the tuning loop).\n",
      "2023-04-06 23:16:33,897\tERROR checkpoint_manager.py:170 -- The requested checkpoint is not available on this node, most likely because you are using Ray client or disabled checkpoint synchronization. To avoid this, enable checkpoint synchronization to cloud storage by specifying a `SyncConfig`. The checkpoint may be available on a different  node - please check this location on worker nodes: /home/ray/ray_results/TensorflowTrainer_2023-04-06_16-16-14/TensorflowTrainer_072e8_00000_0_2023-04-06_16-16-16/checkpoint_000003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m Result for TensorflowTrainer_072e8_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   _time_this_iter_s: 0.8873341083526611\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   _timestamp: 1680822991\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   _training_iteration: 4\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   date: 2023-04-06_16-16-31\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   done: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   experiment_id: f2d05e60392044ee96706251fcdd2a67\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   experiment_tag: '0'\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   hostname: example-cluster-kuberay-head-8jw8d\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   iterations_since_restore: 4\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   loss: 0.928823709487915\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   mean_squared_error: 0.928823709487915\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   node_ip: 10.8.7.8\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   pid: 999\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   should_checkpoint: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   time_since_restore: 10.116967916488647\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   time_this_iter_s: 0.9077465534210205\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   time_total_s: 10.116967916488647\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   timestamp: 1680822991\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   training_iteration: 4\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   trial_id: 072e8_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   warmup_time: 0.03273630142211914\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=798)\u001b[0m Trial TensorflowTrainer_072e8_00000 completed.\n",
      "{'loss': 0.928823709487915, 'mean_squared_error': 0.928823709487915, '_timestamp': 1680822991, '_time_this_iter_s': 0.8873341083526611, '_training_iteration': 4, 'time_this_iter_s': 0.9077465534210205, 'should_checkpoint': True, 'done': True, 'timesteps_total': None, 'episodes_total': None, 'training_iteration': 4, 'trial_id': '072e8_00000', 'experiment_id': 'f2d05e60392044ee96706251fcdd2a67', 'date': '2023-04-06_16-16-31', 'timestamp': 1680822991, 'time_total_s': 10.116967916488647, 'pid': 999, 'hostname': 'example-cluster-kuberay-head-8jw8d', 'node_ip': '10.8.7.8', 'config': {'train_loop_config': {'lr': 0.001, 'batch_size': 32, 'epochs': 4}}, 'time_since_restore': 10.116967916488647, 'timesteps_since_restore': 0, 'iterations_since_restore': 4, 'warmup_time': 0.03273630142211914, 'experiment_tag': '0'}\n"
     ]
    }
   ],
   "source": [
    "trainer = TensorflowTrainer(\n",
    "    train_loop_per_worker=train_func,\n",
    "    train_loop_config=config,\n",
    "    scaling_config=scaling_config,\n",
    "    datasets={\"train\": train_dataset},\n",
    ")\n",
    "result = trainer.fit()\n",
    "print(result.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8e53a4-3ad6-48d2-b151-f393cc450faa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
