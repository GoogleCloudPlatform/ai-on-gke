{"fsdp_transformer_layer_cls_to_wrap":["GPT2Block", "GPT2MLP", "GPT2Attention"],
 "xla":true,
 "xla_fsdp_settings":{"compute_dtype":"bfloat16",
  "shard_param_on_dim_0":true,
  "pin_layout_in_collective_ops":true
 },
 "xla_fsdp_grad_ckpt":true
}
