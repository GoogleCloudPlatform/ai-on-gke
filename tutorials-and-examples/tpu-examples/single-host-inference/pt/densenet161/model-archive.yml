apiVersion: v1
kind: Pod
metadata:
  name: densenet161-model-archive
  annotations:
    gke-gcsfuse/volumes: "true"
spec:
  serviceAccount: sax-sa
  hostNetwork: false
  restartPolicy: Never
  initContainers:
  - name: collect-artifacts
    image: python:3.10
    volumeMounts:
    - mountPath: "/home/model-server/"
      name: tmp-storage
    command:
    - bash
    - -c
    - |
      cd /home/model-server
      CWD="$(pwd)"
      WORKDIR="${CWD}"
      mkdir -p ${WORKDIR}/model-store
      mkdir -p ${WORKDIR}/logs
      echo set WORKDIR for the demo!
      echo ${WORKDIR}

      git clone https://github.com/pytorch/serve.git

      cp ${CWD}/serve/examples/image_classifier/densenet_161/model.py ${WORKDIR}
      cp ${CWD}/serve/examples/image_classifier/index_to_name.json ${WORKDIR}
      echo Download and copy model artifacts from TorchServe image classifier example!

      sudo apt install wget
      wget https://download.pytorch.org/models/densenet161-8d451a50.pth -O densenet161-8d451a50.pth

      mv densenet161-8d451a50.pth ${WORKDIR}
      echo Download the model weights!

      echo 'pt2: "torchxla_trace_once"' >> ${WORKDIR}/model_config.yaml
      echo Create a TorchServe model config file to use the Dynamo backend!

      echo "inference_address=http://0.0.0.0:8080
      management_address=http://0.0.0.0:8081
      metrics_address=http://0.0.0.0:8082
      model_store=/home/model-server/model-store
      load_models=Densenet161.mar
      min_workers=1
      max_workers=1
      default_workers_per_model=1" > config.properties
      echo Create the TorchServe config.properties file!

      ls ${WORKDIR}
  containers:
  - name: archive-model
    image: us-docker.pkg.dev/cloud-tpu-images/inference/torchserve-tpu:v0.8.2-20230829
    command:
    - bash
    - -c
    - |
      torch-model-archiver \
        --model-name Densenet161 \
        --version 1.0 \
        --model-file model.py \
        --serialized-file densenet161-8d451a50.pth \
        --handler image_classifier \
        --export-path model-store \
        --extra-files index_to_name.json \
        --config-file model_config.yaml
      echo got model for the demo!
      mkdir -p /models/pytorch/
      rm -rf /home/model-server/serve
      cp -r /home/model-server/* /models/pytorch/
      ls /models/pytorch/model-store
    volumeMounts:
    - mountPath: "/home/model-server/"
      name: tmp-storage
    - mountPath: "/models/"
      name: external-storage
  volumes:
  - name: tmp-storage
    emptyDir: {}
  - name: external-storage
    persistentVolumeClaim:
      claimName: external-storage-pvc
