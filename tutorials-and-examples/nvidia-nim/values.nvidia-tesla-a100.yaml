initContainers:
  ngcInit:
    imageName: ${REGION}-docker.pkg.dev/${PROJECT_ID}/nim-demo-repo/nemollm-inference-ms
    imageTag: 23.12.a
    secretName: ngc-api
    env:
      STORE_MOUNT_PATH: /model-store
      NGC_CLI_ORG: ohlfw0olaadg
      NGC_CLI_TEAM: ea-participants
      NGC_MODEL_NAME: llama-2-7b-chat
      NGC_MODEL_VERSION: LLAMA-2-7B-CHAT-4K-FP16.23.12.a
      NGC_EXE: ngc
      DOWNLOAD_NGC_CLI: "true"
      NGC_CLI_VERSION: "3.34.1"
      TARFILE: yes
      MODEL_NAME: llama-2-7b-chat

image:
  tag: 23.12.a

imagePullSecrets:
  - name: registry-secret

model:
  numGpus: 1
  name: llama-2-7b-chat

persistence:
  enabled: false
  existingClaim: "model-store-pvc"
  annotations:
    helm.sh/resource-policy: keep

resources:
  limits:
    nvidia.com/gpu: 1

nodeSelector:
  cloud.google.com/gke-nodepool: a2-highgpu-1g-node-pool

service:
  type: ClusterIP
  http_port: 8000  # exposes http interface used in healthchecks to the service
  grpc_port: 8001  # exposes the triton grpc interface
  metrics_port: 8002 # exposes the triton metric interface
  openai_port: 8005
  nemo_port: 8006

serviceAccount:
  create: false  # Specifies whether a service account should be created
  annotations: {} # Annotations to add to the service account
  name: "nim-demo" # The name of the service account to use.