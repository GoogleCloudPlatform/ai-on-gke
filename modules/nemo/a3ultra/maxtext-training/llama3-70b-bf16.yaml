hardware: gpu
dcn_data_parallelism: 2
dcn_fsdp_parallelism: 8
ici_fsdp_parallelism: 8
per_device_batch_size: 2
max_target_length: 8192
learning_rate: 0.001
model_name: llama3.1-70b
enable_checkpointing: false
attention: cudnn_flash_te
remat_policy: save_dot_with_context_except_mlp
use_iota_embed: true
scan_layers: true
dataset_type: synthetic
logits_dot_in_fp32: false
enable_goodput_recording: false
monitor_goodput: false
save_config_to_gcs: true
