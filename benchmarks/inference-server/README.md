>[!WARNING]
>This guide and associated code are **deprecated** and no longer maintained.
>
>Please refer to the [GKE AI Labs website](https://gke-ai-labs.dev) for the latest tutorials and quick start solutions.

This directory contains the inference server specific setup and the
Terraform templates associated with them.

The current supported options are:
- Text Generation Inference (aka TGI)
- TensorRT-LLM on Triton Inference Server 

You may also choose to manually deploy your own inference server.

To deploy an inference server, cd into the respective directory and follow
instructions on the respective README.md