# Copyright 2024 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

image:
  # Replace this with your own image if needed.
  repository: rayproject/ray
  tag: 2.7.1-py310-gpu
  pullPolicy: IfNotPresent

nameOverride: "kuberay"
fullnameOverride: ""

imagePullSecrets: []
# - name: an-existing-secret

head:
  groupName: headgroup
    # If enableInTreeAutoscaling is true, the autoscaler sidecar will be added to the Ray head pod.
    # Ray autoscaler integration is supported only for Ray versions >= 1.11.0
    # Ray autoscaler integration is Beta with KubeRay >= 0.3.0 and Ray >= 2.0.0.
    # enableInTreeAutoscaling: true
    # autoscalerOptions is an OPTIONAL field specifying configuration overrides for the Ray autoscaler.
    # The example configuration shown below below represents the DEFAULT values.
    # autoscalerOptions:
    # upscalingMode: Default
    # idleTimeoutSeconds: 60
    # securityContext: {}
    # env: []
    # envFrom: []
    # resources specifies optional resource request and limit overrides for the autoscaler container.
    # For large Ray clusters, we recommend monitoring container resource usage to determine if overriding the defaults is required.
    # resources:
    #   limits:
    #     cpu: "500m"
    #     memory: "512Mi"
    #   requests:
    #     cpu: "500m"
  #     memory: "512Mi"
  labels:
    cloud.google.com/gke-ray-node-type: head
    created-by: ray-on-gke
  rayStartParams:
    dashboard-host: '0.0.0.0'
    block: 'true'
  # containerEnv specifies environment variables for the Ray container,
  # Follows standard K8s container env schema.
  image:
    repository: rayproject/ray  
    tag: 2.7.1-py310
    pullPolicy: IfNotPresent  
  containerEnv:
  # - name: EXAMPLE_ENV
  #   value: "1"
  - name: RAY_memory_monitor_refresh_ms
    value: "0"
  envFrom: []
    # - secretRef:
  #     name: my-env-secret
  # ports optionally allows specifying ports for the Ray container.
  ports: []
  # resource requests and limits for the Ray head container.
  # Modify as needed for your application.
  # Note that the resources in this example are much too small for production;
  # we don't recommend allocating less than 8G memory for a Ray pod in production.
  # Ray pods should be sized to take up entire K8s nodes when possible.
  # Always set CPU and memory limits for Ray pods.
  # It is usually best to set requests equal to limits.
  # See https://docs.ray.io/en/latest/cluster/kubernetes/user-guides/config.html#resources
  # for further guidance.
  resources:
    limits:
      cpu: "4"
      # To avoid out-of-memory issues, never allocate less than 2G memory for the Ray head.
      memory: "10G"
      ephemeral-storage: 20Gi
    requests:
      cpu: "4"
      memory: "10G"
      ephemeral-storage: 10Gi
  annotations: {}
  nodeSelector:
    iam.gke.io/gke-metadata-server-enabled: "true"
  tolerations:
  - key: "reserved"
    operator: "Exists"
    effect: "NoSchedule"
  affinity: {}
  # Ray container security context.
  securityContext: {}
  volumes:
  - name: ray-logs
    emptyDir: {}
  - name: fluentbit-config
    configMap:
      name: fluentbit-config
  # Ray writes logs to /tmp/ray/session_latests/logs
  volumeMounts:
  - mountPath: /tmp/ray
    name: ray-logs
  # sidecarContainers specifies additional containers to attach to the Ray pod.
  # Follows standard K8s container spec.
  sidecarContainers:
  - name: fluentbit
    image: fluent/fluent-bit:1.9.6
    # These resource requests for Fluent Bit should be sufficient in production.
    resources:
      requests:
        cpu: 100m
        memory: 128Mi
        ephemeral-storage: 2Gi
      limits:
        cpu: 100m
        memory: 128Mi
        ephemeral-storage: 4Gi
    volumeMounts:
    - mountPath: /tmp/ray
      name: ray-logs
    - mountPath: /fluent-bit/etc/
      name: fluentbit-config

worker:
  # If you want to disable the default workergroup
  # uncomment the line below
  # disabled: true
  groupName: workergroup
  replicas: 1
  type: worker
  labels:
    cloud.google.com/gke-ray-node-type: worker
    created-by: ray-on-gke
  rayStartParams:
    block: 'true'
    resources: '"{\"accelerator_type_l4\": 2}"'
  initContainerImage: 'busybox:1.28'  # Enable users to specify the image for init container. Users can pull the busybox image from their private repositories.
  # Security context for the init container.
  initContainerSecurityContext: {}
  # containerEnv specifies environment variables for the Ray container,
  # Follows standard K8s container env schema.
  containerEnv: []
  # - name: EXAMPLE_ENV
  #   value: "1"
  envFrom: []
    # - secretRef:
  #     name: my-env-secret
  # ports optionally allows specifying ports for the Ray container.
  ports: []
  # resource requests and limits for the Ray head container.
  # Modify as needed for your application.
  # Note that the resources in this example are much too small for production;
  # we don't recommend allocating less than 8G memory for a Ray pod in production.
  # Ray pods should be sized to take up entire K8s nodes when possible.
  # Always set CPU and memory limits for Ray pods.
  # It is usually best to set requests equal to limits.
  # See https://docs.ray.io/en/latest/cluster/kubernetes/user-guides/config.html#resources
  # for further guidance.
  resources:
    limits:
      cpu: "22"
      nvidia.com/gpu: "2"
      memory: "90G"
      ephemeral-storage: 20Gi
    requests:
      cpu: "22"
      nvidia.com/gpu: "2"
      memory: "90G"
      ephemeral-storage: 10Gi
  annotations:
    key: value
  nodeSelector:
    iam.gke.io/gke-metadata-server-enabled: "true"
    cloud.google.com/gke-accelerator: "nvidia-l4"
  tolerations:
  - key: "nvidia.com/gpu"
    operator: "Exists"
    effect: "NoSchedule"
  - key: "reserved"
    operator: "Exists"
    effect: "NoSchedule"
  affinity: {}
  # Ray container security context.
  securityContext: {}
  volumes:
  - name: ray-logs
    emptyDir: {}
  - name: fluentbit-config
    configMap:
      name: fluentbit-config
  # Ray writes logs to /tmp/ray/session_latests/logs
  volumeMounts:
  - mountPath: /tmp/ray
    name: ray-logs
  # sidecarContainers specifies additional containers to attach to the Ray pod.
  # Follows standard K8s container spec.
  sidecarContainers:
  - name: fluentbit
    image: fluent/fluent-bit:1.9.6
    # These resource requests for Fluent Bit should be sufficient in production.
    resources:
      requests:
        cpu: 100m
        memory: 128Mi
        ephemeral-storage: 2Gi
      limits:
        cpu: 100m
        memory: 128Mi
        ephemeral-storage: 4Gi
    volumeMounts:
    - mountPath: /tmp/ray
      name: ray-logs
    - mountPath: /fluent-bit/etc/
      name: fluentbit-config

# The map's key is used as the groupName.
# For example, key:small-group in the map below
# will be used as the groupName
additionalWorkerGroups:
  smallGroup:
    # Disabled by default
    disabled: true
    replicas: 1
    minReplicas: 1
    maxReplicas: 3
    type: worker
    labels: {}
    rayStartParams:
      block: 'true'
    initContainerImage: 'busybox:1.28'  # Enable users to specify the image for init container. Users can pull the busybox image from their private repositories.
    # Security context for the init container.
    initContainerSecurityContext: {}
    # containerEnv specifies environment variables for the Ray container,
    # Follows standard K8s container env schema.
    containerEnv: []
      # - name: EXAMPLE_ENV
    #   value: "1"
    envFrom: []
      # - secretRef:
    #     name: my-env-secret
    # ports optionally allows specifying ports for the Ray container.
    ports: []
    # resource requests and limits for the Ray head container.
    # Modify as needed for your application.
    # Note that the resources in this example are much too small for production;
    # we don't recommend allocating less than 8G memory for a Ray pod in production.
    # Ray pods should be sized to take up entire K8s nodes when possible.
    # Always set CPU and memory limits for Ray pods.
    # It is usually best to set requests equal to limits.
    # See https://docs.ray.io/en/latest/cluster/kubernetes/user-guides/config.html#resources
    # for further guidance.
    resources:
      limits:
        cpu: 1
        memory: "1G"
      requests:
        cpu: 1
        memory: "1G"
    annotations:
      key: value
    nodeSelector: {}
    tolerations:
    - key: "nvidia.com/gpu"
      operator: "Exists"
      effect: "NoSchedule"
    - key: "reserved"
      operator: "Exists"
      effect: "NoSchedule"
    affinity: {}
    # Ray container security context.
    securityContext: {}
    volumes:
    - name: ray-logs
      emptyDir: {}
    - name: fluentbit-config
      configMap:
        name: fluentbit-config
    # Ray writes logs to /tmp/ray/session_latests/logs
    volumeMounts:
    - mountPath: /tmp/ray
      name: ray-logs
    # sidecarContainers specifies additional containers to attach to the Ray pod.
    # Follows standard K8s container spec.
    sidecarContainers:
    - name: fluentbit
      image: fluent/fluent-bit:1.9.6
      # These resource requests for Fluent Bit should be sufficient in production.
      resources:
        requests:
          cpu: 100m
          memory: 128Mi
          ephemeral-storage: 2Gi
        limits:
          cpu: 100m
          memory: 128Mi
          ephemeral-storage: 4Gi
      volumeMounts:
      - mountPath: /tmp/ray
        name: ray-logs
      - mountPath: /fluent-bit/etc/
        name: fluentbit-config

service:
  type: ClusterIP