base_emb_dim: 4096
base_num_query_heads: 32
base_num_kv_heads: 8
base_mlp_dim: 14336
base_num_decoder_layers: 32
head_dim: 128
vocab_size: 32000
enable_dropout: false
logits_via_embedding: false
normalization_layer_epsilon: 0.00001
num_experts: 8
num_experts_per_tok: 2
rope_max_timescale: 1000000
decoder_block: mistral
attention: cudnn_flash_te
dataset_type: synthetic
tokenizer_path: "assets/tokenizer.mistral-v1"
max_target_length: 4096
use_iota_embed: true
reuse_example_batch: 1
enable_checkpointing: false
megablox: false
hardware: gpu
scan_layers: false
per_device_batch_size: 5
remat_policy: custom
logits_dot_in_fp32: false
enable_goodput_recording: false
monitor_goodput: false
query_proj: device
key_proj: device
value_proj: device
out_proj: device
mlpwi_0: device
mlpwi_1: device
mlpwo: device
dcn_fsdp_parallelism: 2
dcn_data_parallelism: 8
dcn_tensor_parallelism: 1
dcn_pipeline_parallelism: 1
ici_fsdp_parallelism: -1
ici_expert_parallelism: 8
ici_tensor_parallelism: 1
ici_data_parallelism: 1
capacity_factor: 1
weight_dtype: bfloat16
save_config_to_gcs: true
